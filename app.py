import streamlit as st
import pickle
import pandas as pd
import numpy as np
import os
import google.generativeai as genai
import re
import pyarabic.araby as araby
from nltk.stem.isri import ISRIStemmer

# ============================================================
# โ๏ธ ุฅุนุฏุงุฏุงุช ุงูุตูุญุฉ (Streamlit Configuration)
# ============================================================
st.set_page_config(
    page_title="ููุณ ุจูุช | NafasBot",
    page_icon="๐ค",
    layout="centered",
    initial_sidebar_state="collapsed"
)

# ุชูุณูู ุงุชุฌุงู ุงููุต ูููููู (RTL) ูุฃู ุงูุชุทุจูู ุนุฑุจู
st.markdown("""
    <style>
    .stApp {
        direction: rtl;
        text-align: right;
    }
    .stChatMessage {
        text-align: right;
    }
    </style>
    """, unsafe_allow_html=True)

# ============================================================
# ๐ ุงูุฎุทูุฉ 1: ููุชุงุญ ุงูุฑุจุท (API Key)
# ============================================================
# ุชู ุงูุญูุงุธ ุนูู ุงูููุชุงุญ ููุง ุทูุจุชู
my_api_key = "AIzaSyCgc326bDm51rHLS6CSDCLfzoQ1Y6Yg0b4"

os.environ["GOOGLE_API_KEY"] = my_api_key
genai.configure(api_key=os.environ["GOOGLE_API_KEY"])

# ุงุณุชุฎุฏุงู ุงูููุฏูู ุงููุญุฏุฏ
model = genai.GenerativeModel('gemini-2.5-flash')

# ============================================================
# ๐ง ุงูุฎุทูุฉ 2: ุชุญููู "ุฏูุงุบ" ุงููุธุงู (Caching ูุชุณุฑูุน ุงูุชุทุจูู)
# ============================================================
# ูุณุชุฎุฏู st.cache_resource ุนุดุงู ูุง ูุญูู ุงููููุงุช ูุน ูู ุฑุณุงูุฉ ุฌุฏูุฏุฉ
@st.cache_resource
def load_nafsbot_brain():
    try:
        with open('svm_model.pkl', 'rb') as f: loaded_model = pickle.load(f)
        with open('vectorizer.pkl', 'rb') as f: loaded_vectorizer = pickle.load(f)
        with open('label_encoder.pkl', 'rb') as f: loaded_encoder = pickle.load(f)
        df_data = pd.read_pickle('dataset_original.pkl')
        return loaded_model, loaded_vectorizer, loaded_encoder, df_data
    except FileNotFoundError:
        return None, None, None, None

loaded_model, loaded_vectorizer, loaded_encoder, df_data = load_nafsbot_brain()

# ุงูุชุญูู ูู ุชุญููู ุงููููุงุช
if loaded_model is None:
    st.error("โ ุฎุทุฃ: ูู ูุชู ุงูุนุซูุฑ ุนูู ูููุงุช ุงูุฐูุงุก (.pkl). ุชุฃูุฏู ูู ูุฌูุฏ ุงููููุงุช ุจุฌุงูุจ ููู app.py")
    st.stop()

# ============================================================
# ๐๏ธ ุฏูุงู ุงููุนุงูุฌุฉ (Pre-processing)
# ============================================================
stemmer = ISRIStemmer()

def normalize_arabic_word(word):
    word = araby.strip_tatweel(word)
    word = araby.strip_tashkeel(word)
    word = re.sub(r'[ุฅุฃุขุง]', 'ุง', word)
    word = re.sub(r'ู', 'ู', word)
    word = re.sub(r'ุค', 'ุก', word)
    word = re.sub(r'ุฆ', 'ุก', word)
    word = re.sub(r'ุฉ', 'ู', word)
    word = re.sub(r'(.)\1{2,}', r'\1', word)
    return word

def stem_arabic_word(text):
    text = normalize_arabic_word(text)
    words = text.split()
    stemmed_words = [stemmer.stem(word) for word in words]
    return " ".join(stemmed_words)

# ============================================================
# ๐ ุงูุฎุทูุฉ 3: ุฏุงูุฉ ุงูุชูุงูู (The Integration Logic)
# ============================================================
def get_nafsbot_response(patient_input):
    """
    ููุณ ุงูุฏุงูุฉ ุงูุฃุตููุฉ ุชูุงูุงู ูุน ุงูุญูุงุธ ุนูู ุงูุจุฑููุจุช ูุงูุชุนูููุงุช
    """
    # ุฃ. ุงูุชุตููู ุจุงุณุชุฎุฏุงู ุงูููุฏูู ุงููุญูู (SVM)
    try:
        processed_text = stem_arabic_word(patient_input)
        vec = loaded_vectorizer.transform([processed_text]).toarray()
        prediction_idx = loaded_model.predict(vec)[0]
        category = loaded_encoder.inverse_transform([prediction_idx])[0]
    except:
        return "ุนุฐุฑุงูุ ุญุฏุซ ุฎุทุฃ ุชููู ูู ุชุญููู ุงููุต."

    # ุจ. ุฌูุจ ุงูุณูุงู ูู ุจูุงูุงุชู (Retrieval)
    if df_data is not None:
        related_data = df_data[df_data['Hierarchical Diagnosis'] == category]
        if not related_data.empty:
            context = related_data.sample(n=min(3, len(related_data)))[['Question', 'Answer']].to_dict('records')
        else:
            context = []
    else:
        context = []

    # ุฌ. ุชุฌููุฒ ุงูุจุฑููุจุช
    context_str = ""
    for item in context:
        context_str += f"- ุญุงูุฉ ุณุงุจูุฉ: {item['Question'][:100]}...\n- ุงูุฅุฌุฑุงุก ุงูุทุจู: {item['Answer'][:200]}...\n\n"

    prompt = f"""
    ุชุตุฑู ูู "ููุณ ุจูุช"ุ ุตุฏูู ููุฑุจ ูุฏุงุนู ููุณู ุญููู.
    ุงููุณุชุฎุฏู ุจููุฑ ุจุญุงูุฉ ุชู ุชุตููููุง ูู: {category}

    ุฅููู ุจุนุถ ุงูุญุงูุงุช ุงูุณุงุจูุฉ ููุฑุฌุน (ุฎุฐ ูููุง ุงููุงุฆุฏุฉ ุจุณ ูุง ุชูุณุฎูุง):
    {context_str}

    ุงููุณุชุฎุฏู ุจูุญูููู: "{patient_input}"

    ุงููุทููุจ ููู:
    1. ุฑุฏ ุนููู ุจููุฌุฉ ุนุงููุฉ ุจูุถุงุก (ูุฑูุจุฉ ูููู) ูุจุฃุณููุจ "ุตุฏูู ูุตุฏููู".
    2. ููู ูุชุนุงุทู ุฌุฏุงูุ ุทูููุ ูุญุณุณู ุฅูู ุฌูุจู ูุณุงูุนู.
    3. ุฃุนุทูู ูุตูุญุฉ ุจุณูุทุฉ ูุนูููุฉ ุจูุงุกู ุนูู ุงูุณูุงู ุงูุทุจู ุจุณ ุจูููุงุช ุจุณูุทุฉ ูุด ูุนูุฏุฉ.
    4. ุฎูู ุงูุฑุฏ ูุตูุฑ ููุจุงุดุฑ (ูู 3 ูู 4 ุฌูู).
    5. ุฃุถู ูุซู ุดุนุจู ุนุฑุจู ุฃู ููุณุทููู ุฒู 'ุงูุตุจุฑ ุฌููู' ุฃู 'ูุง ุจุนุฏ ุงูุถูู ุฅูุง ุงููุฑุฌ' ูุชุดุฌูุน ุงูุตุจุฑ ูุงูุฃูู.
    6. ุงุฐุง ูุงู ููุงู ุงู ููุน ูู ุงููุงุน ููุฉ ุงูููุช ุงู ุงูุฐุงุก ุงูููุณ ุงู ุงูุงูุชุญุงุฑ ุงุนุทู ุงุฌุงุจุงุช ุชุฏุนู ููุบุงูุฉ ูููุฑ ุฑูู ุงูุทูุงุฑุฆ ููุฏุนู ุงูููุณู 0795785095 ุงู ุงูุทูุงุฆ ุงูุนุงูุฉ911 ูู ุงูุงุฑุฏู
    ุฃูุช "ููุณ ุจูุช"ุ ุตุฏูู ุฐูู ููุณุงุนุฏ ููุฏุนู ุงูููุณู ููุท.

    ุชุนูููุงุช ุตุงุฑูุฉ ููููุฉ ุฌุฏุงู:
    1. ุงูุฑุฃ ุฑุณุงูุฉ ุงููุณุชุฎุฏู ุฌูุฏุงู: "{patient_input}"
    2. ุญุฏุฏ ุงูููุถูุน:
        - ุฅุฐุง ูุงู ุงูููุงู ุนู ูุดุงุนุฑุ ุถููุ ุฎููุ ุงูุชุฆุงุจุ ูุถูุถุฉุ ุฃู ุชุญูุฉ (ูุฑุญุจุงุ ูููู): ููู ูุฌุงูุจ ูุตุฏูู ุฏุงุนู.
        - ุฅุฐุง ูุงู ุงูููุงู ุนู (ุทุจุฎุ ุฑูุงุถุฉุ ุณูุงุณุฉุ ุญู ูุงุฌุจุงุชุ ูุนูููุงุช ุนุงูุฉุ ุจูุน ูุดุฑุงุก): **ุชููู ููุฑุงู**.

    3. ูู ุญุงูุฉ ุงูุณุคุงู ุงูุฎุงุฑุฌู (ุบูุฑ ููุณู):
        - ุงุนุชุฐุฑ ุจูุทู ุดุฏูุฏ ูุจุงูุนุงููุฉ.
        - ูู ูู ุฌููุฉ ุจูุนูู: "ุณุงูุญูู ูุง ุบุงููุ ุฃูุง ููู ุจุณ ุนุดุงู ุฃุณูุนู ูุฃุฏุนูู ููุณูุงูุ ูุง ุนูุฏู ุฎุจุฑุฉ ุจููู ููุงุถูุน".
        - ูุง ุชุฌุจ ุนูู ุงูุณุคุงู ุฃุจุฏุงู.

    4. ูู ุญุงูุฉ ุงูููุงู ุงูููุณู ุฃู ุงููุถูุถุฉ:
        - ุชุตููู ุงูุญุงูุฉ: {category}
        - ุงูุณูุงู ุงูุทุจู ูููุณุงุนุฏุฉ: {context_str}
        - ุฑุฏ ุนููู ุจููุฌุฉ ุนุงููุฉ ุจูุถุงุกุ ุจุฃุณููุจ ุตุฏูู ููุฑุจ ูุญูููุ ูุทููู.
    """

    # ุฏ. ุงูุงุชุตุงู ุจู Gemini
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        return f"ุนุฐุฑุงูุ ุญุฏุซุช ูุดููุฉ ูู ุงูุงุชุตุงู: {e}"

# ============================================================
# ๐ป ูุงุฌูุฉ ุงูุชุทุจูู (UI Application)
# ============================================================

st.title("๐ค ููุณ ุจูุช | NafasBot")
st.markdown("### ุฑูููู ุงูุฐูู ููุฏุนู ุงูููุณู ๐")
st.caption("ูุถูุถ ูุฃูุง ุจุณูุนู.. ูุณุงุญุชู ุงูุขููุฉ ููุญุฏูุซ.")

# 1. ุชููุฆุฉ ุณุฌู ุงููุญุงุฏุซุฉ (Session State)
if "messages" not in st.session_state:
    st.session_state.messages = []

# 2. ุนุฑุถ ุงูุฑุณุงุฆู ุงููุฏููุฉ ูู ุงูุดุงุดุฉ
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 3. ุงุณุชูุจุงู ูุฏุฎูุงุช ุงููุณุชุฎุฏู (Chat Input)
if prompt := st.chat_input("ุจูุงุฐุง ุชุดุนุฑ ุงููููุ"):
    # ุนุฑุถ ุฑุณุงูุฉ ุงููุณุชุฎุฏู
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # ูุนุงูุฌุฉ ุงูุฑุฏ ูู ุงูุจูุช
    with st.chat_message("assistant"):
        with st.spinner("ููุณ ุจูุช ููุชุจ..."):
            response_text = get_nafsbot_response(prompt)
            st.markdown(response_text)
    
    # ุญูุธ ุฑุฏ ุงูุจูุช ูู ุงูุณุฌู
    st.session_state.messages.append({"role": "assistant", "content": response_text})

# ุฅุถุงูุฉ ุฒุฑ ููุณุญ ุงููุญุงุฏุซุฉ ูู ุงููุงุฆูุฉ ุงูุฌุงูุจูุฉ
with st.sidebar:
    st.info("๐ก ูุฐุง ุจูุช ุชุฌุฑูุจู ููุณุงุนุฏุฉ ูุดุฑูุน ุงูุชุฎุฑุฌ.")
    if st.button("ุจุฏุก ูุญุงุฏุซุฉ ุฌุฏูุฏุฉ"):
        st.session_state.messages = []
        st.rerun()
